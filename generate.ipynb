{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a948e278-2a95-46b5-9453-f037310c32b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9474fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = 'cache'\n",
    "USE_CHAT_HISTORY = False\n",
    "PRINT_QA = False\n",
    "TUTORIALS = [1, 2, 3, 4]\n",
    "MODEL_NAME = \"dragonfly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99dd7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drege/mambaforge/envs/dragonfly_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/drege/mambaforge/envs/dragonfly_env/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Vision Encoder\n"
     ]
    }
   ],
   "source": [
    "if MODEL_NAME == \"dragonfly\":\n",
    "    from models.dragonfly import Dragonfly\n",
    "    model = Dragonfly(use_history=USE_CHAT_HISTORY, cache_dir=CACHE_DIR)\n",
    "elif MODEL_NAME == \"cogagent\":\n",
    "    from models.cogagent import CogAgent\n",
    "    model = CogAgent(use_history=USE_CHAT_HISTORY, cache_dir=CACHE_DIR)\n",
    "else:\n",
    "    from models.internvl import InternVL\n",
    "    assert MODEL_NAME in InternVL.VARIANTS.keys(), f\"Keys are {InternVL.VARIANTS.keys()}\"\n",
    "    model = InternVL(model_name=MODEL_NAME, use_history=USE_CHAT_HISTORY, cache_dir=CACHE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c14aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_foldername = 'history' if USE_CHAT_HISTORY else 'no_history'\n",
    "res_folder = Path('results') / MODEL_NAME.lower() / final_foldername\n",
    "if not res_folder.is_dir():\n",
    "    res_folder.mkdir(parents=True)\n",
    "\n",
    "initial_prompt = \"You are a gamer. You are playing a game tutorial. I will provide you some screenshots of the tutorial. Answer the questions related to the screenshot. Be concise and direct.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a01f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_path(basepath: Path, frame: str) -> str:\n",
    "    filepath = basepath / f'{frame}.png'\n",
    "    if not filepath.is_file():\n",
    "        filepath = basepath / f'{frame}:.png'\n",
    "    assert filepath.is_file(), f'File {str(filepath)} not found!'\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cce6216-64e8-493a-93db-88d40076cc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]/home/drege/mambaforge/envs/dragonfly_env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 9/9 [00:22<00:00,  2.51s/it]\n",
      " 83%|████████▎ | 5/6 [00:09<00:02,  2.40s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:14<00:00,  2.45s/it]\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.53s/it]\n",
      "100%|██████████| 7/7 [00:17<00:00,  2.51s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]/home/drege/mambaforge/envs/dragonfly_env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 10/10 [00:28<00:00,  2.84s/it]\n",
      "100%|██████████| 8/8 [00:20<00:00,  2.53s/it]\n",
      "100%|██████████| 5/5 [00:14<00:00,  2.90s/it]\n",
      "100%|██████████| 11/11 [00:27<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "for revision in ['8832ec1f3d1e27aebefa9228dbbc57474edd94cb', 'last']: \n",
    "    postfix_export = '' if not USE_CHAT_HISTORY else '_with_history'\n",
    "    filename = f'{MODEL_NAME.lower()}_{revision[:7]}{postfix_export}'\n",
    "    BASEPATH = Path(f'data/frames/{revision}')\n",
    "\n",
    "    original = pl.read_csv(BASEPATH / \"frame_labels.csv\").drop_nulls()\n",
    "    original = (\n",
    "        original.group_by(\"frame\")\n",
    "        .agg(pl.col(\"*\"))\n",
    "        .with_columns(\n",
    "            pl.exclude(\"frame\")\n",
    "            .map_elements(\n",
    "                lambda x: [f\"{n}) {q}\" for q, n in zip(x, range(1, len(x) + 1))],\n",
    "                return_dtype=pl.List(pl.Utf8),\n",
    "            )\n",
    "            .list.join(\"\\n\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    responses = []\n",
    "    for tutorial in TUTORIALS:\n",
    "        model.clean_history()\n",
    "        filtered = original.filter(pl.col(\"frame\").str.starts_with(str(tutorial))).sort(\n",
    "            \"frame\"\n",
    "        )\n",
    "        for i, (frame_label, questions, expectation) in tqdm(\n",
    "            enumerate(filtered.iter_rows()), total=filtered.height\n",
    "        ):\n",
    "            img_path = get_img_path(BASEPATH, frame_label)\n",
    "\n",
    "            question = (\n",
    "                f\"{initial_prompt}\\n{questions}\"\n",
    "                if i == 0 or not USE_CHAT_HISTORY\n",
    "                else questions\n",
    "            )\n",
    "            resp = model.generate(img_path, question)\n",
    "\n",
    "            if PRINT_QA:\n",
    "                print(\"@\" * 10)\n",
    "                print(f\"Frame: {frame_label}\")\n",
    "                print(f\"Question: {questions}\")\n",
    "                print(f\"Expectation: {expectation}\")\n",
    "                print(f\"Response: {resp}\")\n",
    "                print(\"@\" * 10)\n",
    "\n",
    "            resp = {\n",
    "                \"frame\": frame_label,\n",
    "                \"question\": questions,\n",
    "                \"expectation\": expectation,\n",
    "                \"reply\": resp,\n",
    "            }\n",
    "\n",
    "            responses.append(resp)\n",
    "            if not USE_CHAT_HISTORY:\n",
    "                model.clean_history()\n",
    "\n",
    "    pl.DataFrame(responses).write_csv(res_folder / f\"{filename}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
